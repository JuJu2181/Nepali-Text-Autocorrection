{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nepali Text Autocorrection System\n",
    "\n",
    "### Author: [Anish Shilpakar](https://github.com/JuJu2181)\n",
    "\n",
    "## About this project\n",
    "Text autocorrection system is a software application that is designed to automatically correct errors in text input by suggesting the most appropriate corrections. The system uses algorithms to analyze the input text and compare it with a database of correct words, phrases or sentences, and provides suggestions for corrections in real-time.\n",
    "\n",
    "Text autocorrection systems are essential tools for improving the accuracy and efficiency of text-based communication, especially in situations where the input is prone to errors. For example, in mobile devices, text messages, emails, and other applications, text autocorrection can significantly reduce the time required to type and edit text, making it easier and faster for users to communicate.\n",
    "\n",
    "The scope of text autocorrection systems is vast, as it can be used in various applications, including but not limited to social media, instant messaging, search engines, email clients, and document editors. Additionally, text autocorrection systems can be implemented in different languages, making them beneficial for users worldwide, irrespective of their language proficiency. \n",
    "\n",
    "In this project I have implemented a simple text autocorrection system for Nepali language. For this project, I have taken this dataset [Nepali words dictionary](https://www.kaggle.com/datasets/sangamthapa/nepali-dictionary) from Kaggle. This Nepali text autocorrection system utilizes Jaccard Similarity and Levenshtein Distance algorithms to suggest the most similar words to a given input word. By leveraging these algorithms, the system provides accurate and efficient corrections to Nepali text, enhancing the overall user experience. As this system is still in development, it may not be accurate as of now, but it will be improved as time moves on. \n",
    "\n",
    "### Programming Language Used\n",
    "- Python\n",
    "\n",
    "> If you want to contribute to this project, feel free to fork this project and send pull requests for your contributions. And if you like this project, don't forget to leave a ⭐ in this repository\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import textdistance\n",
    "from collections import Counter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the number of words and creating unique vocabulary from the input txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words: 556344\n",
      "Total unique words in vocabulary: 496265\n",
      "First 10 words:\n",
      "['अ', 'पत्रकारको', 'अँ', 'छौँ', 'अँकाइ', 'अँगरखा', 'अँगर्खा', 'अँगार', 'अँगाल्–नु', 'अँगाले']\n",
      "Last 10 words:\n",
      "['पढ्छ', 'लेख्छु', 'लेख्छ', 'लेख्छन', 'लेख्छिन', 'पढ्छिन', 'सीता', 'विद्यालय', 'जानुहुन्छ', 'पुगे']\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "with open('./nepali_dict_words.txt','r',encoding='utf-8') as f:\n",
    "    data = f.read()\n",
    "    words = data.split()\n",
    "vocabulary = set(words)\n",
    "print(f\"Total Words: {len(words)}\")\n",
    "print(f\"Total unique words in vocabulary: {len(vocabulary)}\")\n",
    "print(f\"First 10 words:\\n{words[:10]}\")\n",
    "print(f\"Last 10 words:\\n{words[-10:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print('कमल' in words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the frequency of words from the list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = {}\n",
    "for word in words:\n",
    "    if word not in word_freq.keys():\n",
    "        word_freq[word] = 1\n",
    "    else:\n",
    "        word_freq[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('अ', 3),\n",
       " ('पत्रकारको', 3),\n",
       " ('अँ', 4),\n",
       " ('छौँ', 3),\n",
       " ('अँकाइ', 3),\n",
       " ('अँगरखा', 3),\n",
       " ('अँगर्खा', 3),\n",
       " ('अँगार', 3),\n",
       " ('अँगाल्–नु', 3),\n",
       " ('अँगाले', 3)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq_items = list(word_freq.items())\n",
    "word_freq_items[0:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating probabilities based on frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('अ', 5.392347180880894e-06),\n",
       " ('पत्रकारको', 5.392347180880894e-06),\n",
       " ('अँ', 7.189796241174525e-06),\n",
       " ('छौँ', 5.392347180880894e-06),\n",
       " ('अँकाइ', 5.392347180880894e-06),\n",
       " ('अँगरखा', 5.392347180880894e-06),\n",
       " ('अँगर्खा', 5.392347180880894e-06),\n",
       " ('अँगार', 5.392347180880894e-06),\n",
       " ('अँगाल्–नु', 5.392347180880894e-06),\n",
       " ('अँगाले', 5.392347180880894e-06)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = {}\n",
    "Total = sum(word_freq.values())\n",
    "for word in word_freq.keys():\n",
    "    probs[word] = word_freq[word]/Total \n",
    "list(probs.items())[0:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing an autocorrect function using textdistance package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_autocorrect(input_word, n = 5, dist=\"jac\"):\n",
    "    \"\"\"\n",
    "    **Description**\n",
    "    This function will return top n similar words that could be correction for given word\n",
    "    - Similarity can either be based on Jaccard similarity or based on Levenshtein distance\n",
    "\n",
    "    **Arguments** \n",
    "    input_word: word to be corrected\n",
    "    n: no of corrections suggested for input_word\n",
    "    dist: similarity to be used. Use \"jac\" for Jaccard Similarity and \"lev\" for Levenshtein distance\n",
    "\n",
    "    **Returns**\n",
    "    A dataframe showing the top n suggestions along with their probability and similarity\n",
    "    \"\"\"\n",
    "    if input_word in vocabulary:\n",
    "        print(\"Word is correct, so no correction needed\")\n",
    "        return input_word\n",
    "    else: \n",
    "        if dist == \"jac\":\n",
    "            sim = [1-(textdistance.Jaccard(qval=2).distance(v,input_word)) for v in word_freq.keys()]\n",
    "        elif dist == \"lev\":\n",
    "            sim = [1-(textdistance.levenshtein(v,input_word)) for v in word_freq.keys()]\n",
    "        df = pd.DataFrame.from_dict(probs,orient='index').reset_index() \n",
    "        df = df.rename(columns={'index':'Word',0:'Prob'})\n",
    "        df['Similarity'] = sim \n",
    "        output = df.sort_values(['Similarity','Prob'],ascending=False).head(n)\n",
    "        # return list(output['Word'])[0]\n",
    "        return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input word: नेपाब\n",
      "Possible suggestions for given word\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87235</th>\n",
       "      <td>नेपा</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18743</th>\n",
       "      <td>नेपाल</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80415</th>\n",
       "      <td>बनेपा</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261203</th>\n",
       "      <td>नेपार</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380515</th>\n",
       "      <td>नेपाः</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206423</th>\n",
       "      <td>बनेपाबाट</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18744</th>\n",
       "      <td>नेपाली</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18745</th>\n",
       "      <td>नेपाले</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42546</th>\n",
       "      <td>नेपालाबाट</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74073</th>\n",
       "      <td>सानेपा</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word      Prob  Similarity\n",
       "87235        नेपा  0.000002    0.750000\n",
       "18743       नेपाल  0.000020    0.600000\n",
       "80415       बनेपा  0.000002    0.600000\n",
       "261203      नेपार  0.000002    0.600000\n",
       "380515      नेपाः  0.000002    0.600000\n",
       "206423   बनेपाबाट  0.000002    0.571429\n",
       "18744      नेपाली  0.000014    0.500000\n",
       "18745      नेपाले  0.000005    0.500000\n",
       "42546   नेपालाबाट  0.000002    0.500000\n",
       "74073      सानेपा  0.000002    0.500000"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_word = \"नेपाब\"\n",
    "print(f\"Input word: {input_word}\")\n",
    "print(\"Possible suggestions for given word\")\n",
    "my_autocorrect(input_word, n = 10, dist=\"jac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18743</th>\n",
       "      <td>नेपाल</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87235</th>\n",
       "      <td>नेपा</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261203</th>\n",
       "      <td>नेपार</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380515</th>\n",
       "      <td>नेपाः</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18734</th>\n",
       "      <td>नेता</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18744</th>\n",
       "      <td>नेपाली</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18767</th>\n",
       "      <td>नेवा</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10685</th>\n",
       "      <td>चेपाइ</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10688</th>\n",
       "      <td>चेपाङ</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15244</th>\n",
       "      <td>तेजाब</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word      Prob  Similarity\n",
       "18743    नेपाल  0.000020           0\n",
       "87235     नेपा  0.000002           0\n",
       "261203   नेपार  0.000002           0\n",
       "380515   नेपाः  0.000002           0\n",
       "18734     नेता  0.000040          -1\n",
       "18744   नेपाली  0.000014          -1\n",
       "18767     नेवा  0.000007          -1\n",
       "10685    चेपाइ  0.000005          -1\n",
       "10688    चेपाङ  0.000005          -1\n",
       "15244    तेजाब  0.000005          -1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_autocorrect(\"नेपाब\", n = 10, dist=\"lev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4841</th>\n",
       "      <td>कमल</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4848</th>\n",
       "      <td>कमलो</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>कमला</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79094</th>\n",
       "      <td>कमले</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190737</th>\n",
       "      <td>कमली</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word      Prob  Similarity\n",
       "4841     कमल  0.000005    0.666667\n",
       "4848    कमलो  0.000007    0.500000\n",
       "4842    कमला  0.000005    0.500000\n",
       "79094   कमले  0.000002    0.500000\n",
       "190737  कमली  0.000002    0.500000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_autocorrect(\"कमलृ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4848</th>\n",
       "      <td>कमलो</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4841</th>\n",
       "      <td>कमल</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>कमला</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79094</th>\n",
       "      <td>कमले</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190737</th>\n",
       "      <td>कमली</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word      Prob  Similarity\n",
       "4848    कमलो  0.000007           0\n",
       "4841     कमल  0.000005           0\n",
       "4842    कमला  0.000005           0\n",
       "79094   कमले  0.000002           0\n",
       "190737  कमली  0.000002           0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_autocorrect(\"कमलृ\", dist=\"lev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word is correct, so no correction needed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'कम'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_autocorrect(\"कम\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word is correct, so no correction needed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'क'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_autocorrect(\"क\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32097</th>\n",
       "      <td>सब</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32099</th>\n",
       "      <td>सबल</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32108</th>\n",
       "      <td>सबै</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22807</th>\n",
       "      <td>बइन</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100861</th>\n",
       "      <td>सबक</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word      Prob  Similarity\n",
       "32097    सब  0.000009    0.500000\n",
       "32099   सबल  0.000005    0.333333\n",
       "32108   सबै  0.000005    0.333333\n",
       "22807   बइन  0.000004    0.333333\n",
       "100861  सबक  0.000002    0.333333"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_autocorrect(\"सबइ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32097</th>\n",
       "      <td>सब</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32099</th>\n",
       "      <td>सबल</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32108</th>\n",
       "      <td>सबै</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32746</th>\n",
       "      <td>साइ</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100861</th>\n",
       "      <td>सबक</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word      Prob  Similarity\n",
       "32097    सब  0.000009           0\n",
       "32099   सबल  0.000005           0\n",
       "32108   सबै  0.000005           0\n",
       "32746   साइ  0.000005           0\n",
       "100861  सबक  0.000002           0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_autocorrect(\"सबइ\",dist=\"lev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17706</th>\n",
       "      <td>नमाज</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36848</th>\n",
       "      <td>ऐनमा</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37569</th>\n",
       "      <td>रनमा</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47428</th>\n",
       "      <td>उनमा</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50514</th>\n",
       "      <td>मनमा</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word      Prob  Similarity\n",
       "17706  नमाज  0.000005    0.666667\n",
       "36848  ऐनमा  0.000002    0.666667\n",
       "37569  रनमा  0.000002    0.666667\n",
       "47428  उनमा  0.000002    0.666667\n",
       "50514  मनमा  0.000002    0.666667"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_autocorrect(\"नमा\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>आमा</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3804</th>\n",
       "      <td>उमा</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26566</th>\n",
       "      <td>मा</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>अमा</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17698</th>\n",
       "      <td>नमः</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word      Prob  Similarity\n",
       "2644   आमा  0.000011           0\n",
       "3804   उमा  0.000007           0\n",
       "26566   मा  0.000007           0\n",
       "1542   अमा  0.000005           0\n",
       "17698  नमः  0.000005           0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_autocorrect(\"नमा\",dist=\"lev\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Text Autocorrection Feature from Scratch\n",
    "Reference: Coursera NLP Specialization Course"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get frequency of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 496265 key value pairs\n"
     ]
    }
   ],
   "source": [
    "def get_frequency_of_words(words):\n",
    "    word_count_dict = {}\n",
    "    for word in words:\n",
    "        if word in word_count_dict:\n",
    "            word_count_dict[word] += 1\n",
    "        else:\n",
    "            word_count_dict[word] = 1 \n",
    "    return word_count_dict\n",
    "\n",
    "word_count_dict = get_frequency_of_words(words)\n",
    "print(f\"There are {len(word_count_dict)} key value pairs\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get probability of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs(word_count_dict):\n",
    "    probs = {}\n",
    "    total = sum(word_count_dict.values())\n",
    "    for key in word_count_dict.keys():\n",
    "        probs[key] = word_count_dict[key]/total \n",
    "    return probs "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_word = \"नेपाब\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word in vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ेपाब', 'नपाब', 'नेाब', 'नेपब', 'नेपा']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def delete_letter(word):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the string/word for which you will generate all possible words \n",
    "                in the vocabulary which have 1 missing character\n",
    "    Output:\n",
    "        delete_l: a list of all possible strings obtained by deleting 1 character from word\n",
    "    '''\n",
    "    \n",
    "    delete_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    split_l = [(word[:i],word[i:]) for i in range(len(word)+1)]\n",
    "    #split_l is of form [(L1,R1),(L2,R2),...]\n",
    "    delete_l = [L+R[1:] for L,R in split_l if R]\n",
    "\n",
    "    return  delete_l\n",
    "\n",
    "delete_word_l = delete_letter(word=test_word)\n",
    "delete_word_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ेनपाब', 'नपेाब', 'नेापब', 'नेपबा']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SwitchLetter:swap two adjacent letters\n",
    "def switch_letter(word):\n",
    "    '''\n",
    "    Input:\n",
    "        word: input string\n",
    "     Output:\n",
    "        switches: a list of all possible strings with one adjacent charater switched\n",
    "    ''' \n",
    "    \n",
    "    switch_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    split_l = [(word[:i],word[i:]) for i in range(len(word)+1)]\n",
    "    switch_l = [L+R[1]+R[0]+R[2:] for L,R in split_l if len(R) >= 2] \n",
    "    \n",
    "    return switch_l\n",
    "\n",
    "switch_word_l = switch_letter(word=test_word)\n",
    "switch_word_l"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have only considered these alphabets as unique alphabets but there are more alphabets in Nepali "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabets = \"ञज्ञघङझछटठडढणत्रधभचतथगषयउसपवजनमकबशहअखदलफर\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace_letter: changes one letter to another\n",
    "def replace_letter(word):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        replaces: a list of all possible strings where we replaced one letter from the original word. \n",
    "    ''' \n",
    "    \n",
    "    letters = alphabets\n",
    "    \n",
    "    replace_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    split_l = [(word[:i],word[i:]) for i in range(len(word)+1) if len(word[i:]) >= 1]\n",
    "    replace_l = [L + c + R[1:] if len(R) >= 2 else L+c for L,R in split_l for c in letters]\n",
    "    replace_set = set(replace_l)\n",
    "    replace_set.discard(word)\n",
    "    \n",
    "    # turn the set back into a list and sort it, for easier viewing\n",
    "    replace_l = sorted(list(replace_set))\n",
    "        \n",
    "    return replace_l\n",
    "\n",
    "replace_l = replace_letter(word=test_word)\n",
    "len(replace_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert_letter: adds additional characters\n",
    "def insert_letter(word):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        inserts: a set of all possible strings with one new letter inserted at every offset\n",
    "    ''' \n",
    "    letters = alphabets\n",
    "    insert_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    split_l = [(word[:i],word[i:]) for i in range(len(word)+1)]\n",
    "    insert_l = [L + c + R for L,R in split_l for c in letters]\n",
    "    \n",
    "    return insert_l\n",
    "\n",
    "insert_l = insert_letter(word=test_word)\n",
    "len(insert_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_one_letter(word, allow_switches = True):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        word: the string/word for which we will generate all possible wordsthat are one edit away.\n",
    "    Output:\n",
    "        edit_one_set: a set of words with one possible edit. Please return a set. and not a list.\n",
    "    \"\"\"\n",
    "    \n",
    "    edit_one_set = set()\n",
    "    \n",
    "    edit_one_set = set(delete_letter(word)).union(set(switch_letter(word)), set(replace_letter(word)), set(insert_letter(word)))\n",
    "    \n",
    "    # return this as a set and not a list\n",
    "    return set(edit_one_set)\n",
    "\n",
    "def edit_two_letters(word, allow_switches = True):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        edit_two_set: a set of strings with all possible two edits\n",
    "    '''\n",
    "    \n",
    "    edit_two_set = set()\n",
    "    \n",
    "    tmp_edit_one_set = edit_one_letter(word)\n",
    "    tmp_edit_one_list = list(tmp_edit_one_set)\n",
    "    edit_two_list = [edit_one_letter(w) for w in tmp_edit_one_list]\n",
    "    for s in edit_two_list:\n",
    "        edit_two_set.update(s)\n",
    "    \n",
    "    # return this as a set instead of a list\n",
    "    return set(edit_two_set)\n",
    "\n",
    "def get_corrections(word, probs, vocab, n=2):\n",
    "    '''\n",
    "    Input: \n",
    "        word: a user entered string to check for suggestions\n",
    "        probs: a dictionary that maps each word to its probability in the corpus\n",
    "        vocab: a set containing all the vocabulary\n",
    "        n: number of possible word corrections you want returned in the dictionary\n",
    "    Output: \n",
    "        n_best: a list of tuples with the most probable n corrected words and their probabilities.\n",
    "    '''\n",
    "    \n",
    "    suggestions = []\n",
    "    n_best = []\n",
    "    \n",
    "    #Step 1: create suggestions as described above   \n",
    "    if word in vocab:\n",
    "        return [[word,1]]\n",
    "    else:\n",
    "        suggestions = list(edit_one_letter(word).intersection(vocab) or edit_two_letters(word).intersection(\n",
    "                vocab))\n",
    "    # print(suggestions)\n",
    "    #Step 2: determine probability of suggestions\n",
    "    \n",
    "    #Step 3: Get all your best words and return the most probable top n_suggested words as n_best\n",
    "    \n",
    "    n_best = [[s, probs[s]] for s in list(reversed(suggestions))]\n",
    "    \n",
    "\n",
    "    return n_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_word1 = \"नेपा\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nep_autocorrect(my_word):\n",
    "    probs = get_probs(word_count_dict)\n",
    "    tmp_corrections = get_corrections(my_word, probs, vocabulary, 2)\n",
    "    print(f\"Probable words for {my_word} are: \")\n",
    "    for i, word_prob in enumerate(tmp_corrections):\n",
    "        print(f\"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probable words for नेपाब are: \n",
      "word 0: नेपार, probability 0.000002\n",
      "word 1: नेपाल, probability 0.000020\n",
      "word 2: नेपा, probability 0.000002\n"
     ]
    }
   ],
   "source": [
    "my_word = test_word\n",
    "nep_autocorrect(my_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probable words for नेपा are: \n",
      "word 0: नेपा, probability 1.000000\n"
     ]
    }
   ],
   "source": [
    "my_word = test_word1\n",
    "nep_autocorrect(my_word)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding Minimum edit distance and number of edits needed to transform the given word to reference word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_edit_distance(source, target, ins_cost = 1, del_cost = 1, rep_cost = 2):\n",
    "    '''\n",
    "    Input: \n",
    "        source: a string corresponding to the string you are starting with\n",
    "        target: a string corresponding to the string you want to end with\n",
    "        ins_cost: an integer setting the insert cost\n",
    "        del_cost: an integer setting the delete cost\n",
    "        rep_cost: an integer setting the replace cost\n",
    "    Output:\n",
    "        D: a matrix of len(source)+1 by len(target)+1 containing minimum edit distances\n",
    "        med: the minimum edit distance (med) required to convert the source string to the target\n",
    "    '''\n",
    "    # use deletion and insert cost as  1\n",
    "    m = len(source) \n",
    "    n = len(target) \n",
    "    #initialize cost matrix with zeros and dimensions (m+1,n+1) \n",
    "    D = np.zeros((m+1, n+1), dtype=int) \n",
    "    \n",
    "    \n",
    "    # Fill in column 0, from row 1 to row m, both inclusive\n",
    "    for row in range(1,m+1): # Replace None with the proper range\n",
    "        D[row,0] = D[row-1,0] + del_cost\n",
    "        \n",
    "    # Fill in row 0, for all columns from 1 to n, both inclusive\n",
    "    for col in range(1,n+1): # Replace None with the proper range\n",
    "        D[0,col] = D[0,col-1] + ins_cost\n",
    "        \n",
    "    # Loop through row 1 to row m, both inclusive\n",
    "    for row in range(1,m+1): \n",
    "        \n",
    "        # Loop through column 1 to column n, both inclusive\n",
    "        for col in range(1,n+1):\n",
    "            \n",
    "            # Intialize r_cost to the 'replace' cost that is passed into this function\n",
    "            r_cost = rep_cost\n",
    "            \n",
    "            # Check to see if source character at the previous row\n",
    "            # matches the target character at the previous column, \n",
    "            if source[row-1] == target[col-1]:\n",
    "                # Update the replacement cost to 0 if source and target are the same\n",
    "                r_cost = 0\n",
    "                \n",
    "            # Update the cost at row, col based on previous entries in the cost matrix\n",
    "            # Refer to the equation calculate for D[i,j] (the minimum of three calculated costs)\n",
    "            D[row,col] = min([D[row-1,col]+del_cost, D[row,col-1]+ins_cost, D[row-1,col-1]+r_cost])\n",
    "          \n",
    "    # Set the minimum edit distance with the cost found at row m, column n\n",
    "    med = D[m,n]\n",
    "    \n",
    "    return D, med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum edits:  2 \n",
      "\n",
      "   #  न  े  प  ा  ल\n",
      "#  0  1  2  3  4  5\n",
      "न  1  0  1  2  3  4\n",
      "े  2  1  0  1  2  3\n",
      "प  3  2  1  0  1  2\n",
      "ा  4  3  2  1  0  1\n",
      "ब  5  4  3  2  1  2\n"
     ]
    }
   ],
   "source": [
    "source =  'नेपाब'\n",
    "target = 'नेपाल'\n",
    "matrix, min_edits = min_edit_distance(source, target)\n",
    "print(\"minimum edits: \",min_edits, \"\\n\")\n",
    "idx = list('#' + source)\n",
    "cols = list('#' + target)\n",
    "df = pd.DataFrame(matrix, index=idx, columns= cols)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".aivenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6aa66c812e617fe7a976665f04a60359ca2a7b0fa520cb928d0804dda4cd71e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
